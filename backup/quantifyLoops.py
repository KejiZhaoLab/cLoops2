#!/usr/bin/env python
#--coding:utf-8 --
"""
quantifyLoops.py
Get the loop density estimation for different data with the same loop set. 
"""

__date__ = "2019-10-08"
__modified__ = ""
__email__ = "caoyaqiang0410@gmail.com"

#general library
import os
import sys
import json
import argparse
from glob import glob
from datetime import datetime
from argparse import RawTextHelpFormatter

#3rd library
import numpy as np
import pandas as pd
from tqdm import tqdm
from joblib import Parallel, delayed
from scipy.stats import hypergeom, binom, poisson

#cLoops2
from cLoops2.ds import XY, Loop
from cLoops2.io import parseTxt2Loops, ixy2pet
from cLoops2.callCisLoops import getPerRegions, estAnchorSig
from cLoops2.settings import *


def help():
    """
    Create the command line interface for the script.
    """
    description = """
        Quantify the loop density.
        Other file except _loops.txt could be also used, as long as 
        contains key information as fisrt several columns as following,
        seperate by \\t with the header line
        loopId\tchrA\tstartA\tendA\tchrB\tstartB\tendB\tdistance\n
        Example:
        quantifyLoops.py -d GM12878_Trac -l GM12878_Trac_loops.txt -o GM12878_Trac
        """
    parser = argparse.ArgumentParser(description=description,
                                     formatter_class=RawTextHelpFormatter)
    parser.add_argument("-d",
                        dest="predir",
                        required=True,
                        type=str,
                        help="Directory for cLoops2 pre generated.")
    parser.add_argument("-l",
                        dest="floop",
                        required=True,
                        type=str,
                        help="The _loop.txt .file generated by cLoops2.")
    parser.add_argument("-o",
                        dest="output",
                        required=True,
                        type=str,
                        help="Output prefix.")
    parser.add_argument(
        "-pcut",
        dest="pcut",
        type=int,
        default=0,
        help=
        "Distance cutoff for PETs to filter, default is 0. Can be set as the estimated self-ligation distance cutoff."
    )
    parser.add_argument(
        "-lcut",
        dest="lcut",
        type=int,
        default=0,
        help="Distance cutoff for loops to filter, default is 0.")
    parser.add_argument('-p',
                        dest="cpu",
                        required=False,
                        default=1,
                        type=int,
                        help="Number of CPUs to run the job, default is 1.")
    op = parser.parse_args()
    return op


def quantifyLoops(key, loops, fixy, pcut=0, pseudo=1):
    """
    Estimate the loop density and statstical significance for one chromosomal.
    @param key: str, such as chr21-chr21
    @param loops: list of Loop object
    @param fixy: cLoops2 pre generated .ixy file
    """
    xy = ixy2pet(fixy, cut=pcut)
    N = xy.number
    print("%s \t quantify %s candidate interactions in %s." %
          (datetime.now(), len(loops), key))
    nloops = []
    for loop in tqdm(loops):
        ra, rb, rab = xy.queryLoop(loop.x_start, loop.x_end, loop.y_start,
                                   loop.y_end)
        ra, rb, rab = len(ra), len(rb), len(rab)
        #make sure the anchor are significant
        px, esx = estAnchorSig(xy, loop.x_start, loop.x_end)
        py, esy = estAnchorSig(xy, loop.y_start, loop.y_end)
        loop.x_peak_poisson_p_value = px
        loop.x_peak_es = esx
        loop.y_peak_poisson_p_value = py
        loop.y_peak_es = esy
        lowerra, lowerrb, lowerrab = xy.queryLoop(
            loop.x_start - (loop.x_end - loop.x_start), loop.x_start,
            loop.y_start - (loop.y_end - loop.y_start), loop.y_start)  #p2ll
        loop.P2LL = float(rab) / max(len(lowerrab), pseudo)
        #hypergeometric p-value
        hyp = max([1e-300, hypergeom.sf(rab - 1.0, N, ra, rb)])
        #print(ra,rb,rab, np.log10(loop.distance),N,n)
        loop.ra = ra
        loop.rb = rb
        loop.rab = rab
        #start caculate the permutated background
        nas, nbs = getPerRegions(loop, xy)
        rabs, nbps = [], []
        for na in nas:
            nac = float(len(na))
            for nb in nbs:
                nbc = float(len(nb))
                nrab = float(len(na.intersection(nb)))
                #collect the value for poisson test and binomial test
                if nrab > 0:
                    rabs.append(nrab)
                    den = nrab / (nac * nbc)
                    nbps.append(den)
                else:
                    rabs.append(0)
                    nbps.append(0.0)
        rabs, nbps = np.array(rabs), np.array(nbps)
        if np.median(rabs) > 0:
            mrabs = float(np.median(rabs))
        else:
            mrabs = pseudo
        if np.median(nbps) > 0:
            mbps = np.median(nbps)
        else:
            mbps = 1e-10
        #print(mrabs,mbps,loop.rab,loop.x_end-loop.x_start, loop.y_end-loop.y_start, N)
        #local fdr
        if len(rabs) > 0:
            fdr = len(rabs[rabs > rab]) / float(len(rabs))
        else:
            fdr = 0.0
        #enrichment score
        es = rab / mrabs
        #simple possion test
        pop = max([1e-300, poisson.sf(rab - 1.0, mrabs)])
        #simple binomial test
        #nbp = max([1e-300, binom.sf(rab - 1.0, ra*rb, mbps)]) #the p-value is quit similar to that of cLoops 1 binomial test
        #cLoops1 binomial test
        bp = mbps * ra * rb / N
        nbp = max([1e-300, binom.sf(rab - 1.0, N - rab, bp)])
        loop.FDR = fdr
        loop.ES = es
        loop.density = float(
            loop.rab) / (loop.x_end - loop.x_start + loop.y_end -
                         loop.y_start) / N * 10.0**9
        loop.hypergeometric_p_value = hyp
        loop.poisson_p_value = pop
        loop.binomial_p_value = nbp
        nloops.append(loop)
        #print(ra,rb,rab,mrabs,es,fdr,hyp,pop,nbp,n,nbp2)
    return key, nloops


def loops2txt(loops, fout):
    """
    Converting list of cLoops2.ds.loops objects into txt file.
    """
    with open(fout, "w") as fo:
        header = [
            "loopId", "chrA", "startA", "endA", "chrB", "startB", "endB",
            "distance(bp)", "centerA", "centerB", "readsA", "readsB", "cis",
            "PETs", "density", "enrichmentScore", "P2LL", "FDR",
            "binomialPvalue", "hypergeometricPvalue", "poissonPvalue",
            "poissonPvaluePeakA", "poissonPvaluePeakB"
        ]
        fo.write("\t".join(header) + "\n")
        for i, loop in enumerate(loops):
            line = [
                loop.id,
                loop.chromX,
                loop.x_start,
                loop.x_end,
                loop.chromY,
                loop.y_start,
                loop.y_end,
                loop.distance,
                loop.x_center,
                loop.y_center,
                loop.ra,
                loop.rb,
                loop.cis,
                loop.rab,
                loop.density,
                loop.ES,
                loop.P2LL,
                loop.FDR,
                loop.binomial_p_value,
                loop.hypergeometric_p_value,
                loop.poisson_p_value,
                loop.x_peak_poisson_p_value,
                loop.y_peak_poisson_p_value,
            ]
            fo.write("\t".join(list(map(str, line))) + "\n")


def main():
    op = help()
    loops = parseTxt2Loops(op.floop, cut=op.lcut)
    metaf = op.predir + "/petMeta.json"
    meta = json.loads(open(metaf).read())
    keys = list(meta["data"]["cis"].keys())
    keys = list(set(keys).intersection(set(loops.keys())))
    ds = Parallel(n_jobs=op.cpu)(delayed(quantifyLoops)(
        key,
        loops[key],
        meta["data"]["cis"][key]["ixy"],
        pcut=op.pcut,
    ) for key in keys)
    loops = []
    for d in ds:
        loops.extend(d[1])
    loops2txt(loops, op.output + "_loops.txt")


if __name__ == "__main__":
    main()
